{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a668dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:/Users/jangj/anaconda3/envs/tf/Lib/site-packages')\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad549dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('save/model-fire-whole.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25567882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 134ms/step\n",
      "[0.39825383 0.6017462 ]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "[0.3982538 0.6017462]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[0.39835104 0.601649  ]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "[0.39815998 0.60183996]\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "[0.39788914 0.60211086]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[0.39785752 0.60214245]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[0.39774475 0.6022553 ]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "[0.39759153 0.60240847]\n",
      "1/1 [==============================] - 0s 809us/step\n",
      "[0.39755192 0.6024481 ]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[0.39748776 0.60251224]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[0.39738774 0.60261226]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "[0.39734393 0.60265607]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[0.39728686 0.60271317]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "[0.397348  0.6026521]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[0.39730498 0.602695  ]\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "[0.39731517 0.60268486]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[0.39740548 0.60259455]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[0.3975     0.60249996]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[0.39756984 0.6024302 ]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[0.39763457 0.6023654 ]\n"
     ]
    }
   ],
   "source": [
    "# VideoCapture : 카메라 열기\n",
    "capture = cv2.VideoCapture('fire_videoset/fire_video/fire4.mp4')\n",
    "#capture = cv2.VideoCapture('fire_videoset/non_fire_video/non_fire2.mp4')\n",
    "\n",
    "while True:\n",
    "    # read : 프레임 읽기\n",
    "    # [return]\n",
    "    # 1) 읽은 결과(True / False)\n",
    "    # 2) 읽은 프레임\n",
    "    retval, frame = capture.read()\n",
    "\n",
    "    # 읽은 프레임이 없는 경우 종료\n",
    "    if not retval:\n",
    "        break\n",
    "    \n",
    "    # resize : 이미지 크기 변환\n",
    "    # 1) 변환할 이미지\n",
    "    # 2) 변환할 이미지 크기(가로, 세로)\n",
    "    # - interpolation : 보간법 지정\n",
    "    #   - 보간법 : 알려진 데이터 지점 내에서 새로운 데이터 지점을 구성하는 방식\n",
    "    #   - cv2.INTER_NEAREST : 최근방 이웃 보간법\n",
    "    #   - cv2.INTER_LINEAR(default) : 양선형 보간법(2x2 이웃 픽셀 참조)\n",
    "    #   - cv2.INTER_CUBIC : 3차 회선 보간법(4x4 이웃 픽셀 참조)\n",
    "    #   - cv2.INTER_LANCZOS4 : Lanczos 보간법(8x8 이웃 픽셀 참조)\n",
    "    #   - cv2.INTER_AREA : 픽셀 영역 관계를 이용한 resampling 방법으로 이미지 축소시 효과적\n",
    "    resize_frame = cv2.resize(frame, (512, 512), interpolation=cv2.INTER_NEAREST)\n",
    "    #cvt_frame = cv2.cvtColor(resize_frame, cv2.COLOR_BGR2XYZ)\n",
    "    #gaussian_frame = cv2.GaussianBlur(resize_frame,(1,1),0)\n",
    "    shape_frame = resize_frame.reshape(-1,128,128,3) / 255\n",
    "    labels = [\"fire\",\"non_fire\"]\n",
    "    r = model.predict(shape_frame, batch_size=64, verbose=1)\n",
    "    res = r[0]\n",
    "    print(res)\n",
    "    \n",
    "    # 프레임 출력\n",
    "    cv2.imshow(\"frame\", resize_frame)\n",
    "    \n",
    "    # 'q' 를 입력하면 종료\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 동영상 파일 또는 카메라를 닫고 메모리를 해제\n",
    "capture.release()\n",
    "\n",
    "# 모든 창 닫기\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
